{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84fc31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "from dotenv import load_dotenv\n",
    "import mlflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32db4af5",
   "metadata": {},
   "source": [
    "## MLFlow\n",
    "MLFLow has 4 different applications: Tracking, Registry, Models, Projects. In this script, we'll demo all 4 via a local environment. \n",
    "1. Tracking: we will log hyper-parameters used and metrics for a transfer-learning model tuned to MNIST.  \n",
    "2. Registry: after our tuned model is identified, we will register our model. \n",
    "3. Models: a stored model must be served to deliver value. Models will be leveraged for inference. \n",
    "4. Projects: DS code is packaged to reproduce runs on any platform/machine via Projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6586651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment already exists, setting experiment to mnist-hyperparam-local\n",
      "---------------------\n",
      "Experiment details are:\n",
      "Name: mnist-hyperparam-local\n",
      "Experiment_id: 3\n",
      "Artifact Location: s3://mlflow/3\n",
      "Creation timestamp: 1688063866244\n"
     ]
    }
   ],
   "source": [
    "# mlflow tracking server\n",
    "os.environ['MLFLOW_TRACKING_URI'] = \"http://0.0.0.0:5000\"\n",
    "# mlflow artifact/model store\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://localhost:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'minio_user'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = \"minio_pass\"\n",
    "# optuna hyperparam stores\n",
    "os.environ[\"DB_USER\"] = 'postgres'\n",
    "os.environ[\"DB_PASSWORD\"] = 'postgres_pw'\n",
    "os.environ[\"OPTUNA_DB_NAME\"] = 'optunadb'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "421a36b2",
   "metadata": {},
   "source": [
    "### First we'll build all the functions for our ML pipeline.\n",
    "This'll include functions for data loading, preprocessing, and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensorflow_dataset_training(dataset_str: str):\n",
    "    (xy_train, xy_test), ds_info = tfds.load(\n",
    "        dataset_str,\n",
    "        split=['train', 'test'], shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "    return (xy_train, xy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999038d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mnist_tfds(image, label=None):\n",
    "    # reshape and upsample to 3 channel for transfer learning models\n",
    "    # ... for when no channel information is present\n",
    "    if len(image.shape) != 3:\n",
    "        image = np.dstack((image, image, image))\n",
    "    # ... for when channel is only 1 dimension\n",
    "    if image.shape[2] == 1:\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "    # normalize pixel values\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    # resize with pad for mobilenetv2\n",
    "    image = tf.image.resize_with_pad(image, target_height=224, target_width=224)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(mlflow.pyfunc.PythonModel): \n",
    "    def __init__(self, mlflow_registered_model_name: str = None):\n",
    "        self._model = None\n",
    "        self._mlflow_registered_model_name = mlflow_registered_model_name\n",
    "        self.load()    \n",
    "    @staticmethod\n",
    "    def _build(self, hyperparameters):\n",
    "        ## Build model\n",
    "        # class names for mnist hardcoded\n",
    "        class_names = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    \n",
    "        # set layer regularization for DNN\n",
    "        regularizer = tf.keras.regularizers.l1_l2(hyperparameters['l1'], hyperparameters['l2'])\n",
    "\n",
    "        # load in mobilenetv2 weights and instantiate dense classification head \n",
    "        base_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "        layers = [\n",
    "            hub.KerasLayer(\n",
    "                base_model,\n",
    "                input_shape=(224, 224, 3),\n",
    "                trainable=False,\n",
    "                name='mobilenet_embedding'),\n",
    "            tf.keras.layers.Dense(hyperparameters['num_hidden'],\n",
    "                                  kernel_regularizer=regularizer,\n",
    "                                  activation='relu',\n",
    "                                  name='dense_hidden'),\n",
    "            tf.keras.layers.Dense(len(class_names),\n",
    "                                  kernel_regularizer=regularizer,\n",
    "                                  activation='softmax',\n",
    "                                  name='mnist_prob')\n",
    "        ]\n",
    "\n",
    "        self._model = tf.keras.Sequential(layers, name='mnist-classification')\n",
    "\n",
    "        # compile model \n",
    "        self._model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hyperparameters['learning_rate']),\n",
    "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                            from_logits=False),\n",
    "                            metrics=['accuracy'])\n",
    "        \n",
    "        # base model logging\n",
    "        self._model_base = base_model\n",
    "\n",
    "    def fit_hp_search(self, xy_train, xy_test, hyperparameters):                      \n",
    "        self._build(self, hyperparameters)\n",
    "        # fit model using train/test split to find hyperparams\n",
    "        self._train_history = self._model.fit(xy_train,\n",
    "                                               epochs=hyperparameters['epochs'],\n",
    "                                               validation_data=xy_test)\n",
    "    \n",
    "    def fit_production(self, xy_train, hyperparameters):                      \n",
    "        self._build(self, hyperparameters)\n",
    "        # fit model using all the data \n",
    "        self._train_history = self._model.fit(xy_train,\n",
    "                                               epochs=hyperparameters['epochs'])\n",
    "        \n",
    "    def load(self):\n",
    "        try:\n",
    "            results = mlflow.search_registered_models(\n",
    "                filter_string=f'name = \"{self._mlflow_registered_model_name}\"')\n",
    "            latest_model_details = results[0].latest_versions[0]\n",
    "            self._model = mlflow.pyfunc.load_model(\n",
    "                model_uri=f'{latest_model_details.source}')\n",
    "        except IndexError:\n",
    "            print('No models found.')\n",
    "            self._model = None\n",
    "            return self\n",
    "        \n",
    "    def predict(self, context, model_input: np.ndarray) -> np.ndarray:\n",
    "        image, _ = preprocess_mnist_tfds(model_input)\n",
    "        image = tf.reshape(image, [1, 224, 224, 3])\n",
    "        return self._model.predict(image).argmax()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d567d8d",
   "metadata": {},
   "source": [
    "### Tracking your model\n",
    "#### MLFlow has two levels for organizing projects:\n",
    "1. At the top level we have \"experiments\". These should be named as \"project-task-version\" (e.g. mnist-classification)\n",
    "2. At the lower level we have \"runs\". A run consists of logging hyperparameters and metrics when models are trained. Multiple runs can be stored within an experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b9ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow Tracking requires definition of experiment name AND logged params\n",
    "# Experiment names they should be defined as \"project-task-version\"\n",
    "\n",
    "def set_mlflow_experiment(experiment_name:str, artifact_location: str = None):\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(experiment_name, \n",
    "                                                 artifact_location=artifact_location)\n",
    "    # except mlflow.exceptions.MlflowException as e:\n",
    "    #   if str(e) == f\"Experiment '{experiment_name}' already exists.\":\n",
    "    except:\n",
    "        print(f'Experiment already exists, setting experiment to {experiment_name}')\n",
    "        experiment_info = mlflow.set_experiment(experiment_name)\n",
    "        experiment_id = experiment_info.experiment_id\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "    print(\"---------------------\")\n",
    "    print('Experiment details are:')\n",
    "    print(\"Name: {}\".format(experiment.name))\n",
    "    print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "    print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "    print(\"Creation timestamp: {}\".format(experiment.creation_time))\n",
    "    return experiment_id\n",
    "\n",
    "experiment_name = \"mnist-classification-notebook\"\n",
    "experiment_id = set_mlflow_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74397177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# log a base model \n",
    "hyperparams = {\n",
    "    'learning_rate': 0.01,\n",
    "    'l1': 0.0,\n",
    "    'l2': 0.0, \n",
    "    'num_hidden': 16,\n",
    "    'epochs': 3}\n",
    "\n",
    "# Good practice to explicitly define experiment_id and run_name. \n",
    "# Experiment_id can be extracted from above. \n",
    "# Run name examples (e.g. Linear Regression Default Hyperparams).\n",
    "mlflow_run_name='base_model'\n",
    "with mlflow.start_run(experiment_id=experiment_id, \n",
    "                      run_name=mlflow_run_name) as run:\n",
    "    # You can set autolog for tensorflow model.\n",
    "    # Note that autolog does not allow logging of any additional params and metrics.\n",
    "    # We'll choose to do manual logging.\n",
    "    # mlflow.tensorflow.autolog()\n",
    "    # preprocess and define batch sizes for tensorflow \n",
    "    ds_train, ds_test = load_tensorflow_dataset_training('mnist')\n",
    "    model = MNIST()\n",
    "    ds_train = ds_train.map(preprocess_mnist_tfds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_train = ds_train.batch(128)\n",
    "    ds_test = ds_test.map(preprocess_mnist_tfds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_test = ds_test.batch(128) \n",
    "\n",
    "    model.fit(ds_train, ds_test, hyperparams)\n",
    "\n",
    "    # MLFlow Tracking parameters\n",
    "    mlflow.log_params(params=hyperparams)\n",
    "    \n",
    "    # MLFlow Tracking metrics \n",
    "    # Logging metrics for each epoch (housed in dictionary)\n",
    "    training_history = model._train_history.history\n",
    "    for epoch in range(0, hyperparams['epochs']):\n",
    "        insert = {}\n",
    "        for metric, value in training_history.items():\n",
    "            insert[metric] = training_history[metric][epoch]\n",
    "        mlflow.log_metrics(metrics=insert, step=epoch+1)\n",
    "\n",
    "    # MLFlow tracking artifact (e.g. model file)\n",
    "    # this will log the model and all its details under run_id/artifacts\n",
    "    mlflow.pyfunc.log_model(python_model=model,\n",
    "                            artifact_path=\"\")\n",
    "\n",
    "    # Close out MLFlow run to prevent any log contamination.\n",
    "    mlflow.end_run(status='FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters search using Optuna\n",
    "# all this code is stashed under the train-pipeline.py function\n",
    "def objective(trial): \n",
    "    \"\"\"\n",
    "    Optuna objective function for tuning transfer learning model\n",
    "    \"\"\"\n",
    "    hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.00001, 0.1, log=True),\n",
    "        'l1': trial.suggest_float('l1', 0.0, 0.05),\n",
    "        'l2': trial.suggest_float('l2', 0.0, 0.05),\n",
    "        'num_hidden': trial.suggest_int('num_hidden', 8, 64),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 3)\n",
    "    }\n",
    "\n",
    "    mnist_model.fit_hp_search(ds_train, ds_test, hyperparams)\n",
    "    training_history = mnist_model._train_history.history\n",
    "    validation_accuracy = training_history['val_accuracy'][-1]\n",
    "    return validation_accuracy\n",
    "\n",
    "# define optuna variables\n",
    "optuna_storage_url=\"postgresql://{}:{}@localhost:5433/{}\".format(\n",
    "            os.environ[\"DB_USER\"],\n",
    "            os.environ[\"DB_PASSWORD\"],\n",
    "            os.environ[\"OPTUNA_DB_NAME\"]\n",
    "        )\n",
    "\n",
    "# create or load optuna study\n",
    "try:\n",
    "    print('loading study...')\n",
    "    study = optuna.load_study(\n",
    "        study_name=experiment_name,\n",
    "        storage=optuna_storage_url,\n",
    "    )  \n",
    "except KeyError:\n",
    "    print('no study found. building from scratch...')\n",
    "    study = optuna.create_study(\n",
    "        study_name=experiment_name,\n",
    "        storage=optuna_storage_url,\n",
    "        pruner=optuna.pruners.HyperbandPruner(),\n",
    "        direction='maximize')\n",
    "\n",
    "# preprocess and define batch sizes for tensorflow \n",
    "ds_train, ds_test = load_tensorflow_dataset_training('mnist')\n",
    "ds_train = ds_train.map(preprocess_mnist_tfds, \n",
    "                        num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_test = ds_test.map(preprocess_mnist_tfds, \n",
    "                        num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128) \n",
    "\n",
    "mnist_model = model.MNIST()\n",
    "\n",
    "# a new experiment name will be created in MLFlow using the Optuna study name\n",
    "mlflow_kwargs = {'experiment_id': experiment_id}\n",
    "study.optimize(objective,\n",
    "                n_trials=2,\n",
    "                n_jobs=2,\n",
    "                callbacks=[MLflowCallback(metric_name=\"val_accuracy\",\n",
    "                                            create_experiment=False,\n",
    "                                            mlflow_kwargs=mlflow_kwargs)]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f915bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.load_study(\n",
    "    study_name=optuna_study_name,\n",
    "    storage=optuna_storage_url,\n",
    ")  \n",
    "hyperparameters = study.best_params\n",
    "\n",
    "# log the hyper parameter tuned model \n",
    "# No need to set experiment ID if you've set above. \n",
    "# Set a run name here(e.g. Linear Regression Default Hyperparams).\n",
    "mlflow_run_name='optuna_hyperparameter_tuned'\n",
    "with mlflow.start_run(experiment_id=experiment_id, \n",
    "                      run_name=mlflow_run_name) as run:\n",
    "    # load the full dataset for training in production\n",
    "    ds_train = load_tensorflow_dataset_production('mnist')\n",
    "    ds_train = ds_train.map(preprocess_mnist_tfds, \n",
    "                            num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_train = ds_train.batch(128)\n",
    "\n",
    "    # fit model without validation since we're using all the data\n",
    "    model.fit_production(xy_train=ds_train,\n",
    "                        hyperparameters=hyperparameters)\n",
    "\n",
    "    # MLFlow Tracking parameters\n",
    "    mlflow.log_params(params=hyperparameters)\n",
    "    \n",
    "    # MLFlow Tracking metrics \n",
    "    # Logging metrics for each epoch (housed in dictionary)\n",
    "    training_history = model._train_history.history\n",
    "    for epoch in range(0, hyperparams['epochs']):\n",
    "        insert = {}\n",
    "        for metric, value in training_history.items():\n",
    "            insert[metric] = training_history[metric][epoch]\n",
    "        mlflow.log_metrics(metrics=insert, step=epoch+1)\n",
    "\n",
    "    # MLFlow tracking artifact (e.g. model file)\n",
    "    # if you want to bake in model registration instead of using the below:\n",
    "    # use the additional parameter of \"registered_model_name=experiment_name\"\n",
    "    mlflow.pyfunc.log_model(python_model=mnist_model,\n",
    "                            artifact_path=\"\")\n",
    "\n",
    "    mlflow.end_run(status='FINISHED')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54fe297d",
   "metadata": {},
   "source": [
    "### Registering your model\n",
    "Once you've run a couple experiments (e.g. hyper parameter tuning) we can select the best model and register that. Model registering just means that we decide this our optimized model to save. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ec055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search runs \n",
    "run = mlflow.search_runs(\n",
    "    experiment_names=[experiment_name],\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.val_accuracy DESC\"],\n",
    ")\n",
    "\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best performing model run_id. This'll be used to register our model\n",
    "best_run_id = run['run_id'][0] \n",
    "\n",
    "# register model after a scanning a couple different runs from your experiment \n",
    "model_name = experiment_name\n",
    "# mlflow.tensorflow.log_model\n",
    "mv = mlflow.register_model(model_uri=f\"runs:/{best_run_id}/\",\n",
    "                           name=model_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b5c3143",
   "metadata": {},
   "source": [
    "### Serving model\n",
    "After we've registered our model, we can now test inference for that model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9493c05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load using artifact path directory\n",
    "results = mlflow.search_registered_models(filter_string=f'name = \"{experiment_name}\"')\n",
    "latest_model_details = results[0].latest_versions[0]\n",
    "model = mlflow.pyfunc.load_model(model_uri=f'{latest_model_details.source}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10ed6ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "True:2 and predicted:8\n"
     ]
    }
   ],
   "source": [
    "# randomly sample and load a MNIST JPEG\n",
    "import os \n",
    "import numpy as np\n",
    "from random import sample\n",
    "from PIL import Image\n",
    "fp = '/Users/jcheung/Documents/GitHub/thin-ML-deployment/app/ml/test_images'\n",
    "files = [f'{fp}/{x}' for x in os.listdir(fp) if x.split('.')[-1] == 'jpg']\n",
    "filename = sample(files, 1)[0]\n",
    "image = np.array(Image.open(filename))\n",
    "\n",
    "# predict using custom mlflow model\n",
    "predicted = model.predict(image)\n",
    "\n",
    "# output and compare results\n",
    "true = filename.split('/')[-1].split('_')[-1][0]\n",
    "\n",
    "print(f'True:{true} and predicted:{predicted}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thick-ML-deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
